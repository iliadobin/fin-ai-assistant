from openai import OpenAI
from tqdm import tqdm
from dotenv import load_dotenv
import os

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
from data_loader import load_data
from embeddings import load_or_create_embeddings
from search import find_most_relevant_article

# –ü–æ–¥–∫–ª—é—á–∞–µ–º –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ü–æ–¥–∫–ª—é—á–∞–µ–º –∫–ª—é—á–∏ –¥–ª—è API
LLM_API_KEY = os.getenv("LLM_API_KEY")
EMBEDDER_API_KEY = os.getenv("EMBEDDER_API_KEY")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–ª—é—á–µ–π
if not EMBEDDER_API_KEY:
    raise ValueError("EMBEDDER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ! –î–æ–±–∞–≤—å—Ç–µ —Å—Ç—Ä–æ–∫—É: EMBEDDER_API_KEY=sk-0y14H33guZQVnRZFVE6BzQ")
if not LLM_API_KEY:
    raise ValueError("LLM_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
EMBEDDINGS_FILE = "embeddings.pkl"
TRAIN_DATA_FILE = "./train_data.csv"
QUESTIONS_FILE = "./questions.csv"
OUTPUT_FILE = "submission.csv"


def answer_generation(question, article_text, api_key):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏ (RAG –ø–æ–¥—Ö–æ–¥).
    
    Args:
        question (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        article_text (str): –¢–µ–∫—Å—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        api_key (str): API –∫–ª—é—á –¥–ª—è LLM –º–æ–¥–µ–ª–∏
        
    Returns:
        str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
    """
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ LLM –º–æ–¥–µ–ª–∏
    client = OpenAI(
        base_url="https://ai-for-finance-hack.up.railway.app/",
        api_key=api_key,
    )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å—Ç–∞—Ç—å–∏
    prompt = f"""–¢—ã - —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –±–∞–Ω–∫–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞–≤–∞—Ç—å —Ç–æ—á–Ω—ã–µ –∏ –≥—Ä–∞–º–æ—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö –∏ —É—Å–ª—É–≥–∞—Ö.

–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞. –ù–µ –¥–æ–±–∞–≤–ª—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ —Å—Ç–∞—Ç—å–µ.

–°–¢–ê–¢–¨–Ø:
{article_text}

–í–û–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê:
{question}

–î–∞–π —á–µ—Ç–∫–∏–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –Ω–æ –∫—Ä–∞—Ç–∫–∏–º (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."""

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
    response = client.chat.completions.create(
        model="openrouter/mistralai/mistral-small-3.2-24b-instruct",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
    )
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
    return response.choices[0].message.content


if __name__ == "__main__":
    print("\n" + "="*80)
    print("–§–ò–ù–ê–ù–°–û–í–´–ô AI-–ê–°–°–ò–°–¢–ï–ù–¢ - RAG —Å–∏—Å—Ç–µ–º–∞")
    print("="*80 + "\n")
    
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("üìÇ –®–∞–≥ 1/4: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    train_data, questions = load_data(TRAIN_DATA_FILE, QUESTIONS_FILE)
    
    # –®–∞–≥ 2: –°–æ–∑–¥–∞–µ–º/–∑–∞–≥—Ä—É–∂–∞–µ–º embeddings –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π
    print("\nüî¢ –®–∞–≥ 2/4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ embeddings...")
    article_embeddings = load_or_create_embeddings(train_data, EMBEDDINGS_FILE, EMBEDDER_API_KEY)
    
    # –®–∞–≥ 3: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã
    print(f"\nü§ñ –®–∞–≥ 3/4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤...")
    print("(—ç—Ç–æ –∑–∞–π–º–µ—Ç ~15-20 –º–∏–Ω—É—Ç)\n")
    
    answer_list = []
    
    for idx, row in tqdm(questions.iterrows(), total=len(questions), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤"):
        current_question = row['–í–æ–ø—Ä–æ—Å']
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é
        relevant_article = find_most_relevant_article(
            current_question,
            train_data,
            article_embeddings,
            EMBEDDER_API_KEY
        )
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏
        answer = answer_generation(
            current_question,
            relevant_article['text'],
            LLM_API_KEY
        )
        
        answer_list.append(answer)
    
    # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüíæ –®–∞–≥ 4/4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    questions['–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å'] = answer_list
    questions.to_csv(OUTPUT_FILE, index=False)
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUTPUT_FILE}")
    print("="*80)

